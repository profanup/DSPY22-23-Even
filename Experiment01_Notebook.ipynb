{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1DW0TjWsJmTj/8xrrrywY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profanup/DSPY22-23-Even/blob/main/Experiment01_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment No : 01**\n",
        "\n",
        "**Aim :** Learn basics of NumPy library for Reading and Preprocessing any external data into python execution pipeline.\n",
        "\n",
        "**Theory :** NumPy is a Python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating in-memory data.\n",
        "\n",
        "The name Pandas has a reference to both Panel Data, and Python Data Analysis and was created by Wes McKinney in 2008. Pandas allows us to analyze big data and make conclusions based on statistical theories. Pandas can clean messy data sets, and make them readable and relevant. Relevant data is very important in any successful data science pipeline.\n",
        "\n",
        "NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more. It provides **ndarray**, a homogeneous *n-dimensional array object*, with methods to efficiently operate on it. NumPy can be used to perform a wide variety of mathematical operations on arrays. It adds *powerful data structures* to Python that guarantee **efficient calculations** with *arrays and matrices* and it supplies an enormous library of high-level mathematical functions that operate on these arrays and matrices.\n",
        "\n",
        "One can install this package with following command deppending upon how you have installed python.\n",
        "\n",
        "```\n",
        "#conda install numpy\n",
        "```\n",
        "OR\n",
        "```\n",
        "#pip3 install numpy\n",
        "```\n",
        "**Working :** Execute all the code cell understand every output. Write comments where every missing to indicate what does that cell do.\n"
      ],
      "metadata": {
        "id": "r4WyIuoc3pCn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGq2SN-ZzEh-"
      },
      "outputs": [],
      "source": [
        "#importing pandas library\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "numpy.__version__"
      ],
      "metadata": {
        "id": "co-Ocw6r55pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Post Experimental Excersize :**\n",
        "\n",
        "Q1.  \n",
        "\n",
        "1.   Explain the role of isnull, notnull functions in data preprocessing.\n",
        "2.   When to use fillna method in data preprocessing step?\n",
        "3.   What does parameter inplace=True means, what will be the effect of making it False ?\n",
        "4.   Name and Explain any three values that method parameter may have in fillna method.\n",
        "\n",
        "[Note: Answer above questions as four separate text cells]\n",
        "\n",
        "5.   Create a excel file containing 4 real numeric columns latitude, longitude, avg_temp, avg_humidity. Add manually 30 reocords and save file as **weather.csv** Upload this to your google drive and load it into a python variable **weather_info**. Show **all statistical** properties of the columns in this data set."
      ],
      "metadata": {
        "id": "ZLMJFmNF6G-r"
      }
    }
  ]
}